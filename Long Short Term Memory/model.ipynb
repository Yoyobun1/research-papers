{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LONG SHORT TERM MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use this to solve the problem of vanishing gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.1307,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#MNIST Dataset\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 2\n",
    "num_epochs = 2\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, \n",
    "                            hidden_size,\n",
    "                            num_layers,\n",
    "                            batch_first=True)\n",
    "        self.fcl = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # output from prev block\n",
    "        h0 = torch.zeros(self.num_layers,\n",
    "                         x.size(0),\n",
    "                         self.hidden_size)\n",
    "\n",
    "        # memory from prev block\n",
    "        c0 = torch.zeros(self.num_layers,\n",
    "                         x.size(0),\n",
    "                         self.hidden_size)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fcl(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, step 100/30000, loss = 2.240078926086426\n",
      "Epoch 1, step 200/30000, loss = 1.3520734310150146\n",
      "Epoch 1, step 300/30000, loss = 1.8166661262512207\n",
      "Epoch 1, step 400/30000, loss = 0.23635633289813995\n",
      "Epoch 1, step 500/30000, loss = 2.2122409343719482\n",
      "Epoch 1, step 600/30000, loss = 0.7011798024177551\n",
      "Epoch 1, step 700/30000, loss = 0.35173436999320984\n",
      "Epoch 1, step 800/30000, loss = 2.6870386600494385\n",
      "Epoch 1, step 900/30000, loss = 1.3084716796875\n",
      "Epoch 1, step 1000/30000, loss = 1.177424430847168\n",
      "Epoch 1, step 1100/30000, loss = 1.1538671255111694\n",
      "Epoch 1, step 1200/30000, loss = 0.34378698468208313\n",
      "Epoch 1, step 1300/30000, loss = 0.21705982089042664\n",
      "Epoch 1, step 1400/30000, loss = 0.24881631135940552\n",
      "Epoch 1, step 1500/30000, loss = 1.2029935121536255\n",
      "Epoch 1, step 1600/30000, loss = 1.4119383096694946\n",
      "Epoch 1, step 1700/30000, loss = 0.35807013511657715\n",
      "Epoch 1, step 1800/30000, loss = 1.425188660621643\n",
      "Epoch 1, step 1900/30000, loss = 1.9035402536392212\n",
      "Epoch 1, step 2000/30000, loss = 0.7113646268844604\n",
      "Epoch 1, step 2100/30000, loss = 0.43738624453544617\n",
      "Epoch 1, step 2200/30000, loss = 2.6206140518188477\n",
      "Epoch 1, step 2300/30000, loss = 0.8314576148986816\n",
      "Epoch 1, step 2400/30000, loss = 0.5488877296447754\n",
      "Epoch 1, step 2500/30000, loss = 0.30914822220802307\n",
      "Epoch 1, step 2600/30000, loss = 2.045140504837036\n",
      "Epoch 1, step 2700/30000, loss = 0.6162921190261841\n",
      "Epoch 1, step 2800/30000, loss = 1.566741943359375\n",
      "Epoch 1, step 2900/30000, loss = 0.3107556700706482\n",
      "Epoch 1, step 3000/30000, loss = 2.092043399810791\n",
      "Epoch 1, step 3100/30000, loss = 0.27477216720581055\n",
      "Epoch 1, step 3200/30000, loss = 0.8622972965240479\n",
      "Epoch 1, step 3300/30000, loss = 0.9500872492790222\n",
      "Epoch 1, step 3400/30000, loss = 2.291450023651123\n",
      "Epoch 1, step 3500/30000, loss = 3.6860053539276123\n",
      "Epoch 1, step 3600/30000, loss = 7.646239280700684\n",
      "Epoch 1, step 3700/30000, loss = 0.04882971942424774\n",
      "Epoch 1, step 3800/30000, loss = 2.785520553588867\n",
      "Epoch 1, step 3900/30000, loss = 0.477186918258667\n",
      "Epoch 1, step 4000/30000, loss = 3.191110610961914\n",
      "Epoch 1, step 4100/30000, loss = 0.5280213952064514\n",
      "Epoch 1, step 4200/30000, loss = 1.454986810684204\n",
      "Epoch 1, step 4300/30000, loss = 1.0830035209655762\n",
      "Epoch 1, step 4400/30000, loss = 0.23653027415275574\n",
      "Epoch 1, step 4500/30000, loss = 3.106428623199463\n",
      "Epoch 1, step 4600/30000, loss = 1.1828830242156982\n",
      "Epoch 1, step 4700/30000, loss = 1.064429521560669\n",
      "Epoch 1, step 4800/30000, loss = 0.7435424327850342\n",
      "Epoch 1, step 4900/30000, loss = 2.21927547454834\n",
      "Epoch 1, step 5000/30000, loss = 0.12331791967153549\n",
      "Epoch 1, step 5100/30000, loss = 1.483970046043396\n",
      "Epoch 1, step 5200/30000, loss = 0.0452142059803009\n",
      "Epoch 1, step 5300/30000, loss = 0.06441277265548706\n",
      "Epoch 1, step 5400/30000, loss = 0.19663666188716888\n",
      "Epoch 1, step 5500/30000, loss = 0.25310370326042175\n",
      "Epoch 1, step 5600/30000, loss = 1.7065610885620117\n",
      "Epoch 1, step 5700/30000, loss = 0.2760724127292633\n",
      "Epoch 1, step 5800/30000, loss = 3.4257099628448486\n",
      "Epoch 1, step 5900/30000, loss = 2.651646137237549\n",
      "Epoch 1, step 6000/30000, loss = 0.9105982780456543\n",
      "Epoch 1, step 6100/30000, loss = 0.22889778017997742\n",
      "Epoch 1, step 6200/30000, loss = 1.2509196996688843\n",
      "Epoch 1, step 6300/30000, loss = 0.3094664514064789\n",
      "Epoch 1, step 6400/30000, loss = 1.03025484085083\n",
      "Epoch 1, step 6500/30000, loss = 0.0582166351377964\n",
      "Epoch 1, step 6600/30000, loss = 0.2444656491279602\n",
      "Epoch 1, step 6700/30000, loss = 0.061704568564891815\n",
      "Epoch 1, step 6800/30000, loss = 0.10537945479154587\n",
      "Epoch 1, step 6900/30000, loss = 0.7155448794364929\n",
      "Epoch 1, step 7000/30000, loss = 0.11014273762702942\n",
      "Epoch 1, step 7100/30000, loss = 1.3035563230514526\n",
      "Epoch 1, step 7200/30000, loss = 0.09091098606586456\n",
      "Epoch 1, step 7300/30000, loss = 1.1328742504119873\n",
      "Epoch 1, step 7400/30000, loss = 0.1745583713054657\n",
      "Epoch 1, step 7500/30000, loss = 0.17761994898319244\n",
      "Epoch 1, step 7600/30000, loss = 3.718944549560547\n",
      "Epoch 1, step 7700/30000, loss = 0.835752010345459\n",
      "Epoch 1, step 7800/30000, loss = 4.2779860496521\n",
      "Epoch 1, step 7900/30000, loss = 3.620077610015869\n",
      "Epoch 1, step 8000/30000, loss = 0.9504992961883545\n",
      "Epoch 1, step 8100/30000, loss = 1.3531644344329834\n",
      "Epoch 1, step 8200/30000, loss = 0.424140989780426\n",
      "Epoch 1, step 8300/30000, loss = 0.13630758225917816\n",
      "Epoch 1, step 8400/30000, loss = 0.2703429162502289\n",
      "Epoch 1, step 8500/30000, loss = 0.4285426437854767\n",
      "Epoch 1, step 8600/30000, loss = 0.370168536901474\n",
      "Epoch 1, step 8700/30000, loss = 0.22142501175403595\n",
      "Epoch 1, step 8800/30000, loss = 0.1281207948923111\n",
      "Epoch 1, step 8900/30000, loss = 0.22662252187728882\n",
      "Epoch 1, step 9000/30000, loss = 0.08793317526578903\n",
      "Epoch 1, step 9100/30000, loss = 0.02733137644827366\n",
      "Epoch 1, step 9200/30000, loss = 0.11941441893577576\n",
      "Epoch 1, step 9300/30000, loss = 0.08873362839221954\n",
      "Epoch 1, step 9400/30000, loss = 3.913896322250366\n",
      "Epoch 1, step 9500/30000, loss = 0.4128172993659973\n",
      "Epoch 1, step 9600/30000, loss = 0.7438672184944153\n",
      "Epoch 1, step 9700/30000, loss = 0.21482177078723907\n",
      "Epoch 1, step 9800/30000, loss = 1.9827289581298828\n",
      "Epoch 1, step 9900/30000, loss = 0.33824336528778076\n",
      "Epoch 1, step 10000/30000, loss = 0.11259303987026215\n",
      "Epoch 1, step 10100/30000, loss = 0.03175938501954079\n",
      "Epoch 1, step 10200/30000, loss = 0.012722505256533623\n",
      "Epoch 1, step 10300/30000, loss = 0.5513774752616882\n",
      "Epoch 1, step 10400/30000, loss = 0.9529917240142822\n",
      "Epoch 1, step 10500/30000, loss = 0.11644050478935242\n",
      "Epoch 1, step 10600/30000, loss = 0.7367188930511475\n",
      "Epoch 1, step 10700/30000, loss = 0.11864687502384186\n",
      "Epoch 1, step 10800/30000, loss = 0.16845744848251343\n",
      "Epoch 1, step 10900/30000, loss = 2.9062442779541016\n",
      "Epoch 1, step 11000/30000, loss = 0.03722354769706726\n",
      "Epoch 1, step 11100/30000, loss = 0.1919911652803421\n",
      "Epoch 1, step 11200/30000, loss = 2.9984915256500244\n",
      "Epoch 1, step 11300/30000, loss = 0.0872264876961708\n",
      "Epoch 1, step 11400/30000, loss = 1.3673624992370605\n",
      "Epoch 1, step 11500/30000, loss = 0.37726718187332153\n",
      "Epoch 1, step 11600/30000, loss = 0.05456820875406265\n",
      "Epoch 1, step 11700/30000, loss = 1.9477267265319824\n",
      "Epoch 1, step 11800/30000, loss = 1.8863756656646729\n",
      "Epoch 1, step 11900/30000, loss = 0.03547047823667526\n",
      "Epoch 1, step 12000/30000, loss = 0.05694698914885521\n",
      "Epoch 1, step 12100/30000, loss = 0.016627473756670952\n",
      "Epoch 1, step 12200/30000, loss = 0.7297027111053467\n",
      "Epoch 1, step 12300/30000, loss = 0.0046505373902618885\n",
      "Epoch 1, step 12400/30000, loss = 0.08343835920095444\n",
      "Epoch 1, step 12500/30000, loss = 0.3136827349662781\n",
      "Epoch 1, step 12600/30000, loss = 0.1300455927848816\n",
      "Epoch 1, step 12700/30000, loss = 0.06636317074298859\n",
      "Epoch 1, step 12800/30000, loss = 2.3238320350646973\n",
      "Epoch 1, step 12900/30000, loss = 0.6858899593353271\n",
      "Epoch 1, step 13000/30000, loss = 0.18088234961032867\n",
      "Epoch 1, step 13100/30000, loss = 1.784138798713684\n",
      "Epoch 1, step 13200/30000, loss = 0.10972461104393005\n",
      "Epoch 1, step 13300/30000, loss = 2.284459352493286\n",
      "Epoch 1, step 13400/30000, loss = 1.9963538646697998\n",
      "Epoch 1, step 13500/30000, loss = 0.8838537931442261\n",
      "Epoch 1, step 13600/30000, loss = 0.11687027662992477\n",
      "Epoch 1, step 13700/30000, loss = 1.8014026880264282\n",
      "Epoch 1, step 13800/30000, loss = 0.6131155490875244\n",
      "Epoch 1, step 13900/30000, loss = 0.7072795033454895\n",
      "Epoch 1, step 14000/30000, loss = 0.044987887144088745\n",
      "Epoch 1, step 14100/30000, loss = 1.4413896799087524\n",
      "Epoch 1, step 14200/30000, loss = 0.19159820675849915\n",
      "Epoch 1, step 14300/30000, loss = 0.0530119352042675\n",
      "Epoch 1, step 14400/30000, loss = 0.3515439033508301\n",
      "Epoch 1, step 14500/30000, loss = 0.02761436440050602\n",
      "Epoch 1, step 14600/30000, loss = 0.6030418872833252\n",
      "Epoch 1, step 14700/30000, loss = 0.009128445759415627\n",
      "Epoch 1, step 14800/30000, loss = 0.08693185448646545\n",
      "Epoch 1, step 14900/30000, loss = 0.1450071632862091\n",
      "Epoch 1, step 15000/30000, loss = 0.5288228988647461\n",
      "Epoch 1, step 15100/30000, loss = 1.3897868394851685\n",
      "Epoch 1, step 15200/30000, loss = 0.010875171981751919\n",
      "Epoch 1, step 15300/30000, loss = 0.04164605587720871\n",
      "Epoch 1, step 15400/30000, loss = 1.0853207111358643\n",
      "Epoch 1, step 15500/30000, loss = 0.10522150248289108\n",
      "Epoch 1, step 15600/30000, loss = 0.024064693599939346\n",
      "Epoch 1, step 15700/30000, loss = 2.3451833724975586\n",
      "Epoch 1, step 15800/30000, loss = 0.1794467568397522\n",
      "Epoch 1, step 15900/30000, loss = 1.273275375366211\n",
      "Epoch 1, step 16000/30000, loss = 0.2467675507068634\n",
      "Epoch 1, step 16100/30000, loss = 0.4592183232307434\n",
      "Epoch 1, step 16200/30000, loss = 1.3792202472686768\n",
      "Epoch 1, step 16300/30000, loss = 0.7488139867782593\n",
      "Epoch 1, step 16400/30000, loss = 0.6573755741119385\n",
      "Epoch 1, step 16500/30000, loss = 0.1130511686205864\n",
      "Epoch 1, step 16600/30000, loss = 0.021084830164909363\n",
      "Epoch 1, step 16700/30000, loss = 0.058461129665374756\n",
      "Epoch 1, step 16800/30000, loss = 0.1008521169424057\n",
      "Epoch 1, step 16900/30000, loss = 0.09282692521810532\n",
      "Epoch 1, step 17000/30000, loss = 0.22409816086292267\n",
      "Epoch 1, step 17100/30000, loss = 0.10227732360363007\n",
      "Epoch 1, step 17200/30000, loss = 0.13444116711616516\n",
      "Epoch 1, step 17300/30000, loss = 0.5981257557868958\n",
      "Epoch 1, step 17400/30000, loss = 0.08860786259174347\n",
      "Epoch 1, step 17500/30000, loss = 1.1260361671447754\n",
      "Epoch 1, step 17600/30000, loss = 1.4010554552078247\n",
      "Epoch 1, step 17700/30000, loss = 0.20258086919784546\n",
      "Epoch 1, step 17800/30000, loss = 1.796143651008606\n",
      "Epoch 1, step 17900/30000, loss = 0.32028159499168396\n",
      "Epoch 1, step 18000/30000, loss = 0.028890250250697136\n",
      "Epoch 1, step 18100/30000, loss = 0.09710554033517838\n",
      "Epoch 1, step 18200/30000, loss = 0.0981743186712265\n",
      "Epoch 1, step 18300/30000, loss = 0.00936078280210495\n",
      "Epoch 1, step 18400/30000, loss = 1.7993779182434082\n",
      "Epoch 1, step 18500/30000, loss = 1.9670692682266235\n",
      "Epoch 1, step 18600/30000, loss = 0.005034012254327536\n",
      "Epoch 1, step 18700/30000, loss = 1.2383838891983032\n",
      "Epoch 1, step 18800/30000, loss = 1.28574800491333\n",
      "Epoch 1, step 18900/30000, loss = 3.253986358642578\n",
      "Epoch 1, step 19000/30000, loss = 0.027416294440627098\n",
      "Epoch 1, step 19100/30000, loss = 0.013672061264514923\n",
      "Epoch 1, step 19200/30000, loss = 0.037330303341150284\n",
      "Epoch 1, step 19300/30000, loss = 0.16171517968177795\n",
      "Epoch 1, step 19400/30000, loss = 0.4581354856491089\n",
      "Epoch 1, step 19500/30000, loss = 3.723876953125\n",
      "Epoch 1, step 19600/30000, loss = 3.641350269317627\n",
      "Epoch 1, step 19700/30000, loss = 2.2157764434814453\n",
      "Epoch 1, step 19800/30000, loss = 0.016743268817663193\n",
      "Epoch 1, step 19900/30000, loss = 1.2526497840881348\n",
      "Epoch 1, step 20000/30000, loss = 0.2974065840244293\n",
      "Epoch 1, step 20100/30000, loss = 0.39457055926322937\n",
      "Epoch 1, step 20200/30000, loss = 0.12303037196397781\n",
      "Epoch 1, step 20300/30000, loss = 0.4243907332420349\n",
      "Epoch 1, step 20400/30000, loss = 0.3100639283657074\n",
      "Epoch 1, step 20500/30000, loss = 0.23545384407043457\n",
      "Epoch 1, step 20600/30000, loss = 1.168087363243103\n",
      "Epoch 1, step 20700/30000, loss = 2.704669237136841\n",
      "Epoch 1, step 20800/30000, loss = 0.6070221066474915\n",
      "Epoch 1, step 20900/30000, loss = 0.005484806373715401\n",
      "Epoch 1, step 21000/30000, loss = 0.311617374420166\n",
      "Epoch 1, step 21100/30000, loss = 0.06233067810535431\n",
      "Epoch 1, step 21200/30000, loss = 0.17676669359207153\n",
      "Epoch 1, step 21300/30000, loss = 0.16066177189350128\n",
      "Epoch 1, step 21400/30000, loss = 2.2500863075256348\n",
      "Epoch 1, step 21500/30000, loss = 0.42595386505126953\n",
      "Epoch 1, step 21600/30000, loss = 0.13698263466358185\n",
      "Epoch 1, step 21700/30000, loss = 1.0962518453598022\n",
      "Epoch 1, step 21800/30000, loss = 0.042938102036714554\n",
      "Epoch 1, step 21900/30000, loss = 0.0075717647559940815\n",
      "Epoch 1, step 22000/30000, loss = 0.009703374467790127\n",
      "Epoch 1, step 22100/30000, loss = 0.11194062978029251\n",
      "Epoch 1, step 22200/30000, loss = 0.7947551608085632\n",
      "Epoch 1, step 22300/30000, loss = 0.35047727823257446\n",
      "Epoch 1, step 22400/30000, loss = 0.009554943069815636\n",
      "Epoch 1, step 22500/30000, loss = 0.15873099863529205\n",
      "Epoch 1, step 22600/30000, loss = 0.0730179101228714\n",
      "Epoch 1, step 22700/30000, loss = 0.4288778007030487\n",
      "Epoch 1, step 22800/30000, loss = 0.7447776198387146\n",
      "Epoch 1, step 22900/30000, loss = 0.42967551946640015\n",
      "Epoch 1, step 23000/30000, loss = 1.4250919818878174\n",
      "Epoch 1, step 23100/30000, loss = 0.34766721725463867\n",
      "Epoch 1, step 23200/30000, loss = 0.32793036103248596\n",
      "Epoch 1, step 23300/30000, loss = 1.2635822296142578\n",
      "Epoch 1, step 23400/30000, loss = 0.056383877992630005\n",
      "Epoch 1, step 23500/30000, loss = 0.7453765273094177\n",
      "Epoch 1, step 23600/30000, loss = 0.22948484122753143\n",
      "Epoch 1, step 23700/30000, loss = 0.5428193807601929\n",
      "Epoch 1, step 23800/30000, loss = 0.03145674616098404\n",
      "Epoch 1, step 23900/30000, loss = 0.24441906809806824\n",
      "Epoch 1, step 24000/30000, loss = 0.058485448360443115\n",
      "Epoch 1, step 24100/30000, loss = 0.09873966872692108\n",
      "Epoch 1, step 24200/30000, loss = 0.23556119203567505\n",
      "Epoch 1, step 24300/30000, loss = 1.248118281364441\n",
      "Epoch 1, step 24400/30000, loss = 0.048482611775398254\n",
      "Epoch 1, step 24500/30000, loss = 0.23902304470539093\n",
      "Epoch 1, step 24600/30000, loss = 0.02371903508901596\n",
      "Epoch 1, step 24700/30000, loss = 2.187026262283325\n",
      "Epoch 1, step 24800/30000, loss = 0.11263026297092438\n",
      "Epoch 1, step 24900/30000, loss = 0.8202100396156311\n",
      "Epoch 1, step 25000/30000, loss = 5.071580410003662\n",
      "Epoch 1, step 25100/30000, loss = 0.4718548357486725\n",
      "Epoch 1, step 25200/30000, loss = 0.5996432900428772\n",
      "Epoch 1, step 25300/30000, loss = 0.13594071567058563\n",
      "Epoch 1, step 25400/30000, loss = 1.2631165981292725\n",
      "Epoch 1, step 25500/30000, loss = 0.5890383124351501\n",
      "Epoch 1, step 25600/30000, loss = 0.05294434353709221\n",
      "Epoch 1, step 25700/30000, loss = 0.0016650697216391563\n",
      "Epoch 1, step 25800/30000, loss = 0.43045932054519653\n",
      "Epoch 1, step 25900/30000, loss = 0.7531893253326416\n",
      "Epoch 1, step 26000/30000, loss = 0.05681204795837402\n",
      "Epoch 1, step 26100/30000, loss = 0.12866516411304474\n",
      "Epoch 1, step 26200/30000, loss = 2.2044336795806885\n",
      "Epoch 1, step 26300/30000, loss = 0.8283621072769165\n",
      "Epoch 1, step 26400/30000, loss = 0.0017982632853090763\n",
      "Epoch 1, step 26500/30000, loss = 0.04647967219352722\n",
      "Epoch 1, step 26600/30000, loss = 0.012270295061171055\n",
      "Epoch 1, step 26700/30000, loss = 0.06883171200752258\n",
      "Epoch 1, step 26800/30000, loss = 0.5344642400741577\n",
      "Epoch 1, step 26900/30000, loss = 0.4727132320404053\n",
      "Epoch 1, step 27000/30000, loss = 0.35399168729782104\n",
      "Epoch 1, step 27100/30000, loss = 2.675992965698242\n",
      "Epoch 1, step 27200/30000, loss = 0.09699442982673645\n",
      "Epoch 1, step 27300/30000, loss = 0.082077257335186\n",
      "Epoch 1, step 27400/30000, loss = 0.023554136976599693\n",
      "Epoch 1, step 27500/30000, loss = 2.1161227226257324\n",
      "Epoch 1, step 27600/30000, loss = 1.6334047317504883\n",
      "Epoch 1, step 27700/30000, loss = 0.019858259707689285\n",
      "Epoch 1, step 27800/30000, loss = 0.09503666311502457\n",
      "Epoch 1, step 27900/30000, loss = 0.0726817324757576\n",
      "Epoch 1, step 28000/30000, loss = 0.18679426610469818\n",
      "Epoch 1, step 28100/30000, loss = 0.37071168422698975\n",
      "Epoch 1, step 28200/30000, loss = 0.1082858219742775\n",
      "Epoch 1, step 28300/30000, loss = 0.10941477864980698\n",
      "Epoch 1, step 28400/30000, loss = 0.007841205224394798\n",
      "Epoch 1, step 28500/30000, loss = 1.9094293117523193\n",
      "Epoch 1, step 28600/30000, loss = 0.1335357278585434\n",
      "Epoch 1, step 28700/30000, loss = 0.21897581219673157\n",
      "Epoch 1, step 28800/30000, loss = 0.09007243067026138\n",
      "Epoch 1, step 28900/30000, loss = 0.004463122226297855\n",
      "Epoch 1, step 29000/30000, loss = 0.05167565867304802\n",
      "Epoch 1, step 29100/30000, loss = 0.2631298303604126\n",
      "Epoch 1, step 29200/30000, loss = 0.03129459172487259\n",
      "Epoch 1, step 29300/30000, loss = 0.24347713589668274\n",
      "Epoch 1, step 29400/30000, loss = 0.042260508984327316\n",
      "Epoch 1, step 29500/30000, loss = 0.06590914726257324\n",
      "Epoch 1, step 29600/30000, loss = 0.05947434529662132\n",
      "Epoch 1, step 29700/30000, loss = 0.09691175818443298\n",
      "Epoch 1, step 29800/30000, loss = 0.07266338169574738\n",
      "Epoch 1, step 29900/30000, loss = 1.9172205924987793\n",
      "Epoch 1, step 30000/30000, loss = 1.745397925376892\n",
      "Epoch 2, step 100/30000, loss = 1.619673728942871\n",
      "Epoch 2, step 200/30000, loss = 0.18104751408100128\n",
      "Epoch 2, step 300/30000, loss = 0.046727973967790604\n",
      "Epoch 2, step 400/30000, loss = 0.03722119703888893\n",
      "Epoch 2, step 500/30000, loss = 0.006556122563779354\n",
      "Epoch 2, step 600/30000, loss = 0.0887991189956665\n",
      "Epoch 2, step 700/30000, loss = 0.1803334653377533\n",
      "Epoch 2, step 800/30000, loss = 0.09520608186721802\n",
      "Epoch 2, step 900/30000, loss = 0.1893574744462967\n",
      "Epoch 2, step 1000/30000, loss = 1.4624817371368408\n",
      "Epoch 2, step 1100/30000, loss = 0.04519481211900711\n",
      "Epoch 2, step 1200/30000, loss = 0.7436318397521973\n",
      "Epoch 2, step 1300/30000, loss = 3.9556679725646973\n",
      "Epoch 2, step 1400/30000, loss = 0.021154306828975677\n",
      "Epoch 2, step 1500/30000, loss = 0.010453462600708008\n",
      "Epoch 2, step 1600/30000, loss = 0.40748122334480286\n",
      "Epoch 2, step 1700/30000, loss = 0.029106326401233673\n",
      "Epoch 2, step 1800/30000, loss = 0.8921380043029785\n",
      "Epoch 2, step 1900/30000, loss = 3.0284435749053955\n",
      "Epoch 2, step 2000/30000, loss = 0.006207864731550217\n",
      "Epoch 2, step 2100/30000, loss = 0.09110048413276672\n",
      "Epoch 2, step 2200/30000, loss = 1.520107626914978\n",
      "Epoch 2, step 2300/30000, loss = 0.5558150410652161\n",
      "Epoch 2, step 2400/30000, loss = 0.062177274376153946\n",
      "Epoch 2, step 2500/30000, loss = 3.2759029865264893\n",
      "Epoch 2, step 2600/30000, loss = 0.043304868042469025\n",
      "Epoch 2, step 2700/30000, loss = 0.10673686861991882\n",
      "Epoch 2, step 2800/30000, loss = 2.994292974472046\n",
      "Epoch 2, step 2900/30000, loss = 0.3026141822338104\n",
      "Epoch 2, step 3000/30000, loss = 2.1273272037506104\n",
      "Epoch 2, step 3100/30000, loss = 0.35523808002471924\n",
      "Epoch 2, step 3200/30000, loss = 0.0398930199444294\n",
      "Epoch 2, step 3300/30000, loss = 1.6008105278015137\n",
      "Epoch 2, step 3400/30000, loss = 0.058804720640182495\n",
      "Epoch 2, step 3500/30000, loss = 0.009628700092434883\n",
      "Epoch 2, step 3600/30000, loss = 0.03455476462841034\n",
      "Epoch 2, step 3700/30000, loss = 0.0012645636452361941\n",
      "Epoch 2, step 3800/30000, loss = 0.7581622004508972\n",
      "Epoch 2, step 3900/30000, loss = 0.12334325909614563\n",
      "Epoch 2, step 4000/30000, loss = 0.10712026059627533\n",
      "Epoch 2, step 4100/30000, loss = 1.3370962142944336\n",
      "Epoch 2, step 4200/30000, loss = 0.057142648845911026\n",
      "Epoch 2, step 4300/30000, loss = 0.17718194425106049\n",
      "Epoch 2, step 4400/30000, loss = 0.7835631370544434\n",
      "Epoch 2, step 4500/30000, loss = 0.0006864693714305758\n",
      "Epoch 2, step 4600/30000, loss = 0.24092641472816467\n",
      "Epoch 2, step 4700/30000, loss = 1.8977108001708984\n",
      "Epoch 2, step 4800/30000, loss = 0.07058659195899963\n",
      "Epoch 2, step 4900/30000, loss = 0.9025687575340271\n",
      "Epoch 2, step 5000/30000, loss = 0.05685396492481232\n",
      "Epoch 2, step 5100/30000, loss = 0.1599280834197998\n",
      "Epoch 2, step 5200/30000, loss = 0.5142015814781189\n",
      "Epoch 2, step 5300/30000, loss = 0.07970349490642548\n",
      "Epoch 2, step 5400/30000, loss = 2.8119516372680664\n",
      "Epoch 2, step 5500/30000, loss = 0.2924621105194092\n",
      "Epoch 2, step 5600/30000, loss = 1.656648874282837\n",
      "Epoch 2, step 5700/30000, loss = 0.014779668301343918\n",
      "Epoch 2, step 5800/30000, loss = 0.09578508138656616\n",
      "Epoch 2, step 5900/30000, loss = 0.13657145202159882\n",
      "Epoch 2, step 6000/30000, loss = 0.17601260542869568\n",
      "Epoch 2, step 6100/30000, loss = 0.0010824970668181777\n",
      "Epoch 2, step 6200/30000, loss = 1.1146972179412842\n",
      "Epoch 2, step 6300/30000, loss = 0.004478286486119032\n",
      "Epoch 2, step 6400/30000, loss = 2.026602029800415\n",
      "Epoch 2, step 6500/30000, loss = 0.21746550500392914\n",
      "Epoch 2, step 6600/30000, loss = 0.10433398187160492\n",
      "Epoch 2, step 6700/30000, loss = 0.01613604836165905\n",
      "Epoch 2, step 6800/30000, loss = 0.05673185735940933\n",
      "Epoch 2, step 6900/30000, loss = 0.5616158246994019\n",
      "Epoch 2, step 7000/30000, loss = 0.0707603171467781\n",
      "Epoch 2, step 7100/30000, loss = 2.13676381111145\n",
      "Epoch 2, step 7200/30000, loss = 0.5250503420829773\n",
      "Epoch 2, step 7300/30000, loss = 3.578639507293701\n",
      "Epoch 2, step 7400/30000, loss = 0.07220612466335297\n",
      "Epoch 2, step 7500/30000, loss = 1.1516307592391968\n",
      "Epoch 2, step 7600/30000, loss = 0.05690312385559082\n",
      "Epoch 2, step 7700/30000, loss = 0.3220733106136322\n",
      "Epoch 2, step 7800/30000, loss = 0.47749242186546326\n",
      "Epoch 2, step 7900/30000, loss = 0.5379216074943542\n",
      "Epoch 2, step 8000/30000, loss = 0.040465354919433594\n",
      "Epoch 2, step 8100/30000, loss = 0.3019757568836212\n",
      "Epoch 2, step 8200/30000, loss = 0.016779044643044472\n",
      "Epoch 2, step 8300/30000, loss = 0.20764987170696259\n",
      "Epoch 2, step 8400/30000, loss = 1.8427735567092896\n",
      "Epoch 2, step 8500/30000, loss = 0.2316093146800995\n",
      "Epoch 2, step 8600/30000, loss = 0.06679607927799225\n",
      "Epoch 2, step 8700/30000, loss = 0.7020196914672852\n",
      "Epoch 2, step 8800/30000, loss = 0.11214806139469147\n",
      "Epoch 2, step 8900/30000, loss = 0.4319078028202057\n",
      "Epoch 2, step 9000/30000, loss = 0.014780351892113686\n",
      "Epoch 2, step 9100/30000, loss = 0.10159822553396225\n",
      "Epoch 2, step 9200/30000, loss = 0.08495720475912094\n",
      "Epoch 2, step 9300/30000, loss = 2.8477320671081543\n",
      "Epoch 2, step 9400/30000, loss = 2.863717794418335\n",
      "Epoch 2, step 9500/30000, loss = 0.016439130529761314\n",
      "Epoch 2, step 9600/30000, loss = 0.13517610728740692\n",
      "Epoch 2, step 9700/30000, loss = 0.21389570832252502\n",
      "Epoch 2, step 9800/30000, loss = 0.009932521730661392\n",
      "Epoch 2, step 9900/30000, loss = 0.09318788349628448\n",
      "Epoch 2, step 10000/30000, loss = 0.6948459148406982\n",
      "Epoch 2, step 10100/30000, loss = 0.1759970486164093\n",
      "Epoch 2, step 10200/30000, loss = 1.0983870029449463\n",
      "Epoch 2, step 10300/30000, loss = 0.062104225158691406\n",
      "Epoch 2, step 10400/30000, loss = 0.08038339018821716\n",
      "Epoch 2, step 10500/30000, loss = 0.7279192209243774\n",
      "Epoch 2, step 10600/30000, loss = 0.8967418670654297\n",
      "Epoch 2, step 10700/30000, loss = 2.8195230960845947\n",
      "Epoch 2, step 10800/30000, loss = 0.0345863401889801\n",
      "Epoch 2, step 10900/30000, loss = 3.49737548828125\n",
      "Epoch 2, step 11000/30000, loss = 1.0163267850875854\n",
      "Epoch 2, step 11100/30000, loss = 0.01620367169380188\n",
      "Epoch 2, step 11200/30000, loss = 0.4845069944858551\n",
      "Epoch 2, step 11300/30000, loss = 0.21006691455841064\n",
      "Epoch 2, step 11400/30000, loss = 0.7426952719688416\n",
      "Epoch 2, step 11500/30000, loss = 5.217711448669434\n",
      "Epoch 2, step 11600/30000, loss = 0.008342905901372433\n",
      "Epoch 2, step 11700/30000, loss = 0.17020876705646515\n",
      "Epoch 2, step 11800/30000, loss = 0.01438534539192915\n",
      "Epoch 2, step 11900/30000, loss = 2.1279919147491455\n",
      "Epoch 2, step 12000/30000, loss = 0.5332715511322021\n",
      "Epoch 2, step 12100/30000, loss = 0.167156383395195\n",
      "Epoch 2, step 12200/30000, loss = 0.06955822557210922\n",
      "Epoch 2, step 12300/30000, loss = 0.6300554275512695\n",
      "Epoch 2, step 12400/30000, loss = 0.4657233655452728\n",
      "Epoch 2, step 12500/30000, loss = 0.024796882644295692\n",
      "Epoch 2, step 12600/30000, loss = 1.0987203121185303\n",
      "Epoch 2, step 12700/30000, loss = 0.2365313619375229\n",
      "Epoch 2, step 12800/30000, loss = 0.7847322225570679\n",
      "Epoch 2, step 12900/30000, loss = 0.029225952923297882\n",
      "Epoch 2, step 13000/30000, loss = 1.7232578992843628\n",
      "Epoch 2, step 13100/30000, loss = 0.5482478737831116\n",
      "Epoch 2, step 13200/30000, loss = 0.036150459200143814\n",
      "Epoch 2, step 13300/30000, loss = 0.7625824809074402\n",
      "Epoch 2, step 13400/30000, loss = 0.37817952036857605\n",
      "Epoch 2, step 13500/30000, loss = 1.0336002111434937\n",
      "Epoch 2, step 13600/30000, loss = 1.804092288017273\n",
      "Epoch 2, step 13700/30000, loss = 0.7434819936752319\n",
      "Epoch 2, step 13800/30000, loss = 0.02890741638839245\n",
      "Epoch 2, step 13900/30000, loss = 0.008738696575164795\n",
      "Epoch 2, step 14000/30000, loss = 2.414829969406128\n",
      "Epoch 2, step 14100/30000, loss = 0.4145129323005676\n",
      "Epoch 2, step 14200/30000, loss = 0.17402327060699463\n",
      "Epoch 2, step 14300/30000, loss = 0.011001771315932274\n",
      "Epoch 2, step 14400/30000, loss = 0.2687906324863434\n",
      "Epoch 2, step 14500/30000, loss = 0.044828444719314575\n",
      "Epoch 2, step 14600/30000, loss = 0.031081456691026688\n",
      "Epoch 2, step 14700/30000, loss = 0.022814687341451645\n",
      "Epoch 2, step 14800/30000, loss = 2.2294816970825195\n",
      "Epoch 2, step 14900/30000, loss = 0.014547674916684628\n",
      "Epoch 2, step 15000/30000, loss = 0.11383479833602905\n",
      "Epoch 2, step 15100/30000, loss = 0.038477879017591476\n",
      "Epoch 2, step 15200/30000, loss = 0.2431122064590454\n",
      "Epoch 2, step 15300/30000, loss = 0.2265690118074417\n",
      "Epoch 2, step 15400/30000, loss = 0.02283100038766861\n",
      "Epoch 2, step 15500/30000, loss = 0.06580274552106857\n",
      "Epoch 2, step 15600/30000, loss = 0.3391222357749939\n",
      "Epoch 2, step 15700/30000, loss = 0.3766695559024811\n",
      "Epoch 2, step 15800/30000, loss = 0.09347257763147354\n",
      "Epoch 2, step 15900/30000, loss = 0.042512618005275726\n",
      "Epoch 2, step 16000/30000, loss = 1.7783294916152954\n",
      "Epoch 2, step 16100/30000, loss = 0.3227074146270752\n",
      "Epoch 2, step 16200/30000, loss = 0.24318622052669525\n",
      "Epoch 2, step 16300/30000, loss = 0.1367546021938324\n",
      "Epoch 2, step 16400/30000, loss = 0.044356994330883026\n",
      "Epoch 2, step 16500/30000, loss = 0.9870156049728394\n",
      "Epoch 2, step 16600/30000, loss = 0.02207328751683235\n",
      "Epoch 2, step 16700/30000, loss = 0.27259522676467896\n",
      "Epoch 2, step 16800/30000, loss = 0.04830572009086609\n",
      "Epoch 2, step 16900/30000, loss = 0.33684155344963074\n",
      "Epoch 2, step 17000/30000, loss = 0.032108839601278305\n",
      "Epoch 2, step 17100/30000, loss = 0.07398775219917297\n",
      "Epoch 2, step 17200/30000, loss = 0.030877139419317245\n",
      "Epoch 2, step 17300/30000, loss = 0.3185546100139618\n",
      "Epoch 2, step 17400/30000, loss = 0.0282841045409441\n",
      "Epoch 2, step 17500/30000, loss = 0.16229815781116486\n",
      "Epoch 2, step 17600/30000, loss = 0.2838810086250305\n",
      "Epoch 2, step 17700/30000, loss = 0.14333286881446838\n",
      "Epoch 2, step 17800/30000, loss = 0.042436763644218445\n",
      "Epoch 2, step 17900/30000, loss = 0.03213263303041458\n",
      "Epoch 2, step 18000/30000, loss = 0.1267591118812561\n",
      "Epoch 2, step 18100/30000, loss = 0.01922159641981125\n",
      "Epoch 2, step 18200/30000, loss = 0.12090224772691727\n",
      "Epoch 2, step 18300/30000, loss = 0.3227160573005676\n",
      "Epoch 2, step 18400/30000, loss = 1.6643508672714233\n",
      "Epoch 2, step 18500/30000, loss = 2.1364996433258057\n",
      "Epoch 2, step 18600/30000, loss = 0.8787155151367188\n",
      "Epoch 2, step 18700/30000, loss = 0.019383175298571587\n",
      "Epoch 2, step 18800/30000, loss = 0.10382969677448273\n",
      "Epoch 2, step 18900/30000, loss = 0.033731985837221146\n",
      "Epoch 2, step 19000/30000, loss = 0.02446102909743786\n",
      "Epoch 2, step 19100/30000, loss = 0.011304733343422413\n",
      "Epoch 2, step 19200/30000, loss = 0.002045937580987811\n",
      "Epoch 2, step 19300/30000, loss = 0.3993009328842163\n",
      "Epoch 2, step 19400/30000, loss = 0.27802222967147827\n",
      "Epoch 2, step 19500/30000, loss = 1.3204240798950195\n",
      "Epoch 2, step 19600/30000, loss = 0.061259545385837555\n",
      "Epoch 2, step 19700/30000, loss = 0.7721905708312988\n",
      "Epoch 2, step 19800/30000, loss = 1.5156540870666504\n",
      "Epoch 2, step 19900/30000, loss = 2.4135589599609375\n",
      "Epoch 2, step 20000/30000, loss = 1.2662947177886963\n",
      "Epoch 2, step 20100/30000, loss = 0.40688973665237427\n",
      "Epoch 2, step 20200/30000, loss = 0.49856045842170715\n",
      "Epoch 2, step 20300/30000, loss = 0.06425391882658005\n",
      "Epoch 2, step 20400/30000, loss = 0.8787068724632263\n",
      "Epoch 2, step 20500/30000, loss = 1.1358424425125122\n",
      "Epoch 2, step 20600/30000, loss = 2.3796706199645996\n",
      "Epoch 2, step 20700/30000, loss = 0.08697402477264404\n",
      "Epoch 2, step 20800/30000, loss = 0.2135479897260666\n",
      "Epoch 2, step 20900/30000, loss = 0.5600550174713135\n",
      "Epoch 2, step 21000/30000, loss = 0.15466947853565216\n",
      "Epoch 2, step 21100/30000, loss = 0.09666997939348221\n",
      "Epoch 2, step 21200/30000, loss = 0.30895787477493286\n",
      "Epoch 2, step 21300/30000, loss = 0.024955593049526215\n",
      "Epoch 2, step 21400/30000, loss = 0.5598148703575134\n",
      "Epoch 2, step 21500/30000, loss = 0.2264658510684967\n",
      "Epoch 2, step 21600/30000, loss = 1.143324375152588\n",
      "Epoch 2, step 21700/30000, loss = 0.5962476134300232\n",
      "Epoch 2, step 21800/30000, loss = 0.10731349140405655\n",
      "Epoch 2, step 21900/30000, loss = 0.13601677119731903\n",
      "Epoch 2, step 22000/30000, loss = 0.3217041492462158\n",
      "Epoch 2, step 22100/30000, loss = 0.0016874298453330994\n",
      "Epoch 2, step 22200/30000, loss = 0.054147686809301376\n",
      "Epoch 2, step 22300/30000, loss = 0.06842359900474548\n",
      "Epoch 2, step 22400/30000, loss = 1.3267133235931396\n",
      "Epoch 2, step 22500/30000, loss = 0.014796556904911995\n",
      "Epoch 2, step 22600/30000, loss = 0.0064346883445978165\n",
      "Epoch 2, step 22700/30000, loss = 0.1048637330532074\n",
      "Epoch 2, step 22800/30000, loss = 0.9587981104850769\n",
      "Epoch 2, step 22900/30000, loss = 0.08853133767843246\n",
      "Epoch 2, step 23000/30000, loss = 0.05879993736743927\n",
      "Epoch 2, step 23100/30000, loss = 0.06118761748075485\n",
      "Epoch 2, step 23200/30000, loss = 0.18530462682247162\n",
      "Epoch 2, step 23300/30000, loss = 1.5107173919677734\n",
      "Epoch 2, step 23400/30000, loss = 0.2279844582080841\n",
      "Epoch 2, step 23500/30000, loss = 0.6323976516723633\n",
      "Epoch 2, step 23600/30000, loss = 0.051819801330566406\n",
      "Epoch 2, step 23700/30000, loss = 1.1586631536483765\n",
      "Epoch 2, step 23800/30000, loss = 0.27632638812065125\n",
      "Epoch 2, step 23900/30000, loss = 0.002960293786600232\n",
      "Epoch 2, step 24000/30000, loss = 0.19177410006523132\n",
      "Epoch 2, step 24100/30000, loss = 0.04750863090157509\n",
      "Epoch 2, step 24200/30000, loss = 0.11406344175338745\n",
      "Epoch 2, step 24300/30000, loss = 0.013747164979577065\n",
      "Epoch 2, step 24400/30000, loss = 0.36859914660453796\n",
      "Epoch 2, step 24500/30000, loss = 0.07587245106697083\n",
      "Epoch 2, step 24600/30000, loss = 0.5482286214828491\n",
      "Epoch 2, step 24700/30000, loss = 0.2469574362039566\n",
      "Epoch 2, step 24800/30000, loss = 0.04582292214035988\n",
      "Epoch 2, step 24900/30000, loss = 0.08064018189907074\n",
      "Epoch 2, step 25000/30000, loss = 0.20770752429962158\n",
      "Epoch 2, step 25100/30000, loss = 0.18903343379497528\n",
      "Epoch 2, step 25200/30000, loss = 0.17473164200782776\n",
      "Epoch 2, step 25300/30000, loss = 0.00702536478638649\n",
      "Epoch 2, step 25400/30000, loss = 1.8109463453292847\n",
      "Epoch 2, step 25500/30000, loss = 0.042521290481090546\n",
      "Epoch 2, step 25600/30000, loss = 0.00720799807459116\n",
      "Epoch 2, step 25700/30000, loss = 0.18236370384693146\n",
      "Epoch 2, step 25800/30000, loss = 0.2502478063106537\n",
      "Epoch 2, step 25900/30000, loss = 0.31729090213775635\n",
      "Epoch 2, step 26000/30000, loss = 0.7062433958053589\n",
      "Epoch 2, step 26100/30000, loss = 1.4295045137405396\n",
      "Epoch 2, step 26200/30000, loss = 0.6447280049324036\n",
      "Epoch 2, step 26300/30000, loss = 0.0021539954468607903\n",
      "Epoch 2, step 26400/30000, loss = 0.165176123380661\n",
      "Epoch 2, step 26500/30000, loss = 0.046657152473926544\n",
      "Epoch 2, step 26600/30000, loss = 1.338227391242981\n",
      "Epoch 2, step 26700/30000, loss = 0.018985051661729813\n",
      "Epoch 2, step 26800/30000, loss = 2.935828924179077\n",
      "Epoch 2, step 26900/30000, loss = 0.3641784191131592\n",
      "Epoch 2, step 27000/30000, loss = 0.9946765899658203\n",
      "Epoch 2, step 27100/30000, loss = 0.012995356693863869\n",
      "Epoch 2, step 27200/30000, loss = 0.03778371959924698\n",
      "Epoch 2, step 27300/30000, loss = 0.03213674947619438\n",
      "Epoch 2, step 27400/30000, loss = 0.25881773233413696\n",
      "Epoch 2, step 27500/30000, loss = 0.18089693784713745\n",
      "Epoch 2, step 27600/30000, loss = 0.02049325779080391\n",
      "Epoch 2, step 27700/30000, loss = 0.728118896484375\n",
      "Epoch 2, step 27800/30000, loss = 0.10387344658374786\n",
      "Epoch 2, step 27900/30000, loss = 0.08567684888839722\n",
      "Epoch 2, step 28000/30000, loss = 0.5474657416343689\n",
      "Epoch 2, step 28100/30000, loss = 1.223894476890564\n",
      "Epoch 2, step 28200/30000, loss = 3.1045403480529785\n",
      "Epoch 2, step 28300/30000, loss = 0.13608451187610626\n",
      "Epoch 2, step 28400/30000, loss = 0.021254118531942368\n",
      "Epoch 2, step 28500/30000, loss = 0.1686561107635498\n",
      "Epoch 2, step 28600/30000, loss = 1.7501145601272583\n",
      "Epoch 2, step 28700/30000, loss = 0.34933793544769287\n",
      "Epoch 2, step 28800/30000, loss = 0.004509200341999531\n",
      "Epoch 2, step 28900/30000, loss = 0.005779162980616093\n",
      "Epoch 2, step 29000/30000, loss = 0.14796753227710724\n",
      "Epoch 2, step 29100/30000, loss = 0.1551857590675354\n",
      "Epoch 2, step 29200/30000, loss = 0.04654139652848244\n",
      "Epoch 2, step 29300/30000, loss = 0.1990390121936798\n",
      "Epoch 2, step 29400/30000, loss = 0.0014464425621554255\n",
      "Epoch 2, step 29500/30000, loss = 0.10367020219564438\n",
      "Epoch 2, step 29600/30000, loss = 0.48336952924728394\n",
      "Epoch 2, step 29700/30000, loss = 0.005694692488759756\n",
      "Epoch 2, step 29800/30000, loss = 0.018942896276712418\n",
      "Epoch 2, step 29900/30000, loss = 0.01570090278983116\n",
      "Epoch 2, step 30000/30000, loss = 0.016183529049158096\n"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, sequence_length, input_size)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)%100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, step {i+1}/{total_steps}, loss = {loss.item()}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy = 85.87\n"
     ]
    }
   ],
   "source": [
    "correct = total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.reshape(-1, sequence_length, input_size)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "print(f\"test accuracy = {100*correct/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
