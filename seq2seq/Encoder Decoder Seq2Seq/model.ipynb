{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq model using tf.keras and Encoder/Decoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Flatten, InputLayer, Input, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to generate a Seq2Seq Dataset and One hot encode and decode input and output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(length, n_unique):\n",
    "    return [randint(1, n_unique-1) for _ in range(length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence, n_unique):\n",
    "\tencoding = list()\n",
    "\tfor value in sequence:\n",
    "\t\tvector = [0 for _ in range(n_unique)]\n",
    "\t\tvector[value] = 1\n",
    "\t\tencoding.append(vector)\n",
    "\treturn np.array(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decode(encoded_seq):\n",
    "    return [np.argmax(vector) for vector in encoded_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reversed_pairs(time_steps, vocabulary_size, verbose=False):\n",
    "    # generate random sequence\n",
    "    sequence_in = generate_sequence(time_steps, vocabulary_size)\n",
    "    sequence_out = sequence_in[::-1]\n",
    "\n",
    "    # one hot encode\n",
    "    X = one_hot_encode(sequence_in, vocabulary_size)\n",
    "    y = one_hot_encode(sequence_out, vocabulary_size)\n",
    "\n",
    "    # reshape as 3D\n",
    "    X = X.reshape(1, X.shape[0], X.shape[1])\n",
    "    y = y.reshape(1, y.shape[0], y.shape[1])\n",
    "\n",
    "    if verbose:\n",
    "        \n",
    "        print(\"Notes\")\n",
    "        print(f\"1. For each input sequence,(X), we select {time_steps} random numbers between 1 and {vocabulary_size - 1}\")\n",
    "        print(\"2. 0 is reserved as the START symbol\")\n",
    "        print()\n",
    "        \n",
    "        print(\"A sample of input: X\")\n",
    "        print(one_hot_decode(X[0]))\n",
    "        print()\n",
    "        \n",
    "        print(\"A sample of output(reverse of X): y\")\n",
    "        print(one_hot_decode(y[0]))\n",
    "        print()\n",
    "        \n",
    "        print(\"X and y in One-hot encoded format\")\n",
    "        print(\"X:\")\n",
    "        print(X[0])\n",
    "        print()\n",
    "        print(\"y:\")\n",
    "        print(y[0])\n",
    "        print()\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(train_size,\n",
    "                   test_size,\n",
    "                   time_steps,\n",
    "                   vocabulary_size,\n",
    "                   verbose=False):\n",
    "    pairs = [get_reversed_pairs(time_steps, vocabulary_size) for _ in range(train_size)]\n",
    "    pairs = np.array(pairs).squeeze()\n",
    "\n",
    "\n",
    "    X_train = pairs[:,0]\n",
    "    y_train = pairs[:,1]\n",
    "\n",
    "    pairs = [get_reversed_pairs(time_steps, vocabulary_size) for _ in range(test_size)]\n",
    "    pairs = np.array(pairs).squeeze()\n",
    "\n",
    "    X_test = pairs[:,0]\n",
    "    y_test = pairs[:,1]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Train data\")\n",
    "        print(X_train.shape)\n",
    "        print(y_train.shape)\n",
    "\n",
    "        print(\"Test data\")\n",
    "        print(X_test.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Train and Test given model (Early stopping monitor = val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp = ModelCheckpoint(\"encoder_decoder_model.keras\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Function to Train & Test  given model (Early Stopping monitor 'val_loss')\n",
    "def train_test(model, X_train, y_train , X_test, \ty_test, epochs=500, batch_size=32, patience=5,verbose=0):\n",
    "\t# patient early stopping\n",
    "\t#es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, patience=20)\n",
    "\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "\tckp = ModelCheckpoint(\"encoder_decoder_model.keras\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    " \n",
    "\t# train model\n",
    "\tprint('training for ',epochs,' epochs begins with EarlyStopping(monitor= val_loss, patience=',patience,')....')\n",
    "\thistory=model.fit(X_train, y_train, validation_split= 0.1, epochs=epochs,batch_size=batch_size, verbose=verbose, callbacks=[es, ckp])\n",
    "\tprint(epochs,' epoch training finished...')\n",
    "\n",
    "\t# report training\n",
    "\t# list all data in history\n",
    "\t#print(history.history.keys())\n",
    "\t# evaluate the model\n",
    "\t_, train_acc = model.evaluate(X_train, y_train, batch_size=batch_size, verbose=0)\n",
    "\t_, test_acc = model.evaluate(X_test, \ty_test, batch_size=batch_size, verbose=0)\n",
    "\tprint('\\nPREDICTION ACCURACY (%):')\n",
    "\tprint('Train: %.3f, Test: %.3f' % (train_acc*100, test_acc*100))\n",
    "\t# summarize history for accuracy\n",
    "\tplt.plot(history.history['accuracy'])\n",
    "\tplt.plot(history.history['val_accuracy'])\n",
    "\tplt.title(model.name+' accuracy')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\t# summarize history for loss\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title(model.name+' loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'val'], loc='upper left')\n",
    "\tplt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\t# spot check some examples\n",
    "\tspace = 3*len(one_hot_decode(y_test[0]))\n",
    "\tprint('10 examples from test data...')\n",
    "\tprint('Input',' '*(space-4) ,'Expected',' '*(space-7) ,\n",
    "\t      'Predicted',' '*(space-5) ,'T/F')\n",
    "\tcorrect = 0 \n",
    "\tsampleNo = 10\n",
    "\n",
    "\tpredicted= model_encoder_decoder.predict(X_test[:sampleNo], batch_size=batch_size)\n",
    "\tfor sample in range(0,sampleNo):\n",
    "\t\tif (one_hot_decode(y_test[sample])== one_hot_decode(predicted[sample])):\n",
    "\t\t\tcorrect+=1\n",
    "\t\tprint( one_hot_decode(X_test[sample]), ' ', \n",
    "\t\t\t\t\tone_hot_decode(y_test[sample]),' ', one_hot_decode(predicted[sample]),\n",
    "\t\t\t\t\t' ',one_hot_decode(y_test[sample])== one_hot_decode(predicted[sample]))\n",
    "\tprint('Accuracy: ', correct/sampleNo)\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes\n",
      "1. For each input sequence,(X), we select 4 random numbers between 1 and 9\n",
      "2. 0 is reserved as the START symbol\n",
      "\n",
      "A sample of input: X\n",
      "[9, 9, 7, 4]\n",
      "\n",
      "A sample of output(reverse of X): y\n",
      "[4, 7, 9, 9]\n",
      "\n",
      "X and y in One-hot encoded format\n",
      "X:\n",
      "[[0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n",
      "\n",
      "y:\n",
      "[[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = 4\n",
    "n_features = 10\n",
    "\n",
    "X,y = get_reversed_pairs(n_timesteps, n_features, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n",
      "(2000, 4, 10)\n",
      "(2000, 4, 10)\n",
      "Test data\n",
      "(200, 4, 10)\n",
      "(200, 4, 10)\n"
     ]
    }
   ],
   "source": [
    "# generate datasets\n",
    "train_size= 2000 #@param {type:\"integer\"}\n",
    "test_size = 200  #@param {type:\"integer\"}\n",
    "\n",
    "X_train, y_train , X_test, \ty_test=create_dataset(train_size, test_size, n_timesteps, n_features , verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfUnits = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Encoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(n_timesteps, n_features),\n",
    "                       name=\"encoder_inputs\")\n",
    "encoder_lstm = LSTM(noOfUnits, return_state=True,\n",
    "                    name=\"encoder_lstm\")\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 16), (None, 16), (None, 16)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives us last hidden state, last hidden state and last cell state\n",
    "encoder_lstm.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context vector = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 10)\n",
      "noOfUnits: 16\n",
      "Last Hidden State: (1, 16)\n",
      "Last Cell State: (1, 16)\n"
     ]
    }
   ],
   "source": [
    "# define and compile encoder\n",
    "model_encoder = Model(inputs = encoder_inputs, outputs = states)\n",
    "context_vector = model_encoder(X)\n",
    "\n",
    "print(X.shape)\n",
    "print(f\"noOfUnits: {noOfUnits}\")\n",
    "print(f\"Last Hidden State: {context_vector[0].numpy().shape}\")\n",
    "print(f\"Last Cell State: {context_vector[1].numpy().shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Decoder LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(1, n_features),\n",
    "                       name = \"decoder_inputs\")\n",
    "\n",
    "decoder_lstm = LSTM(noOfUnits,\n",
    "                    return_sequences=True,\n",
    "                    return_state=True,\n",
    "                    name=\"decoder_lstm\")\n",
    "\n",
    "decoder_dense = Dense(n_features, activation='softmax')\n",
    "\n",
    "outputs, state_h, state_c = decoder_lstm(decoder_inputs,\n",
    "                                         initial_state=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 1, 16), (None, 16), (None, 16)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_lstm.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In raw format:\n",
      "X: [9, 9, 7, 4]\n",
      "y: [4, 7, 9, 9]\n",
      "\n",
      "In one_hot_encoded format:\n",
      "X: \n",
      "[[0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]]\n",
      "\n",
      "y: \n",
      "[[0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#title Sample X and y\n",
    "\n",
    "print('\\nIn raw format:')\n",
    "print(\"X:\",(one_hot_decode(X[0])))\n",
    "print(\"y:\",(one_hot_decode(y[0])))\n",
    "print('\\nIn one_hot_encoded format:')\n",
    "print(\"X: \")\n",
    "print((X[0]))\n",
    "print()\n",
    "print(\"y: \")\n",
    "print((y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hard_coded_decoder_input_model(batch_size):\n",
    "  # The first part is encoder\n",
    "  encoder_inputs = Input(shape=(n_timesteps, n_features), name='encoder_inputs')\n",
    "  encoder_lstm = LSTM(noOfUnits, return_state=True,  name='encoder_lstm')\n",
    "  encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "  \n",
    "  # initial context vector is the states of the encoder\n",
    "  states = [state_h, state_c]\n",
    "  \n",
    "  # Set up the decoder layers\n",
    "  # Attention: decoder receives 1 token at a time &\n",
    "  # decoder outputs 1 token at a time \n",
    "  \n",
    "  decoder_lstm = LSTM(noOfUnits, return_sequences=True, \n",
    "                      return_state=True, name='decoder_lstm')\n",
    "  decoder_dense = Dense(n_features, activation='softmax',  name='decoder_dense')\n",
    "\n",
    "  all_outputs = []\n",
    "  # Prepare decoder initial input data: just contains the START character 0\n",
    "  # Note that we made it a constant one-hot-encoded in the model\n",
    "  # that is, [1 0 0 0 0 0 0 0 0 0] is the initial input for each loop\n",
    "  decoder_input_data = np.zeros((batch_size, 1, n_features))\n",
    "  decoder_input_data[:, 0, 0] = 1 \n",
    "  \n",
    "  # that is, [1 0 0 0 0 0 0 0 0 0] is the initial input for each loop\n",
    "  inputs = decoder_input_data\n",
    "  # decoder will only process one time step at a time\n",
    "  # loops for fixed number of time steps: n_timesteps_in\n",
    "  for _ in range(n_timesteps):\n",
    "      # Run the decoder on one time step\n",
    "      outputs, state_h, state_c = decoder_lstm(inputs,\n",
    "                                              initial_state=states)\n",
    "      outputs = decoder_dense(outputs)\n",
    "      # Store the current prediction (we will concatenate all predictions later)\n",
    "      all_outputs.append(outputs)\n",
    "      # Reinject the outputs as inputs for the next loop iteration\n",
    "      # as well as update the states\n",
    "      inputs = outputs\n",
    "      states = [state_h, state_c]\n",
    "\n",
    "  # Concatenate all predictions such as [batch_size, timesteps, features]\n",
    "  decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "\n",
    "  # Define and compile model \n",
    "  model = Model(encoder_inputs, decoder_outputs, name='encoder_decoder_model')\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_inputs (InputLayer)     [(None, 4, 10)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_lstm (LSTM)             [(None, 16), (None,  1728        encoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_lstm (LSTM)             [(10, 1, 16), (None, 1728        encoder_lstm[0][1]               \n",
      "                                                                 encoder_lstm[0][2]               \n",
      "                                                                 decoder_dense[0][0]              \n",
      "                                                                 decoder_lstm[0][1]               \n",
      "                                                                 decoder_lstm[0][2]               \n",
      "                                                                 decoder_dense[1][0]              \n",
      "                                                                 decoder_lstm[1][1]               \n",
      "                                                                 decoder_lstm[1][2]               \n",
      "                                                                 decoder_dense[2][0]              \n",
      "                                                                 decoder_lstm[2][1]               \n",
      "                                                                 decoder_lstm[2][2]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (10, 1, 10)          170         decoder_lstm[0][0]               \n",
      "                                                                 decoder_lstm[1][0]               \n",
      "                                                                 decoder_lstm[2][0]               \n",
      "                                                                 decoder_lstm[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (10, 4, 10)          0           decoder_dense[0][0]              \n",
      "                                                                 decoder_dense[1][0]              \n",
      "                                                                 decoder_dense[2][0]              \n",
      "                                                                 decoder_dense[3][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,626\n",
      "Trainable params: 3,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "model = create_hard_coded_decoder_input_model(batch_size)\n",
    "model.summary()\n",
    "#plot_model(model, show_shapes=True, show_layer_names=True, to_file='basic_encoder_decoder_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for  500  epochs begins with EarlyStopping(monitor= val_loss, patience= 5 )....\n",
      "Epoch 1/500\n",
      "180/180 [==============================] - 13s 20ms/step - loss: 2.1781 - accuracy: 0.2379 - val_loss: 2.0033 - val_accuracy: 0.3075\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.00332, saving model to encoder_decoder_model.keras\n",
      "Epoch 2/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.8032 - accuracy: 0.3507 - val_loss: 1.6798 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.00332 to 1.67975, saving model to encoder_decoder_model.keras\n",
      "Epoch 3/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.6096 - accuracy: 0.3758 - val_loss: 1.5580 - val_accuracy: 0.3900\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.67975 to 1.55797, saving model to encoder_decoder_model.keras\n",
      "Epoch 4/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.5077 - accuracy: 0.3951 - val_loss: 1.4681 - val_accuracy: 0.3987\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.55797 to 1.46813, saving model to encoder_decoder_model.keras\n",
      "Epoch 5/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 1.4275 - accuracy: 0.4089 - val_loss: 1.3970 - val_accuracy: 0.4050\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.46813 to 1.39701, saving model to encoder_decoder_model.keras\n",
      "Epoch 6/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 1.3645 - accuracy: 0.4183 - val_loss: 1.3362 - val_accuracy: 0.4138\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.39701 to 1.33622, saving model to encoder_decoder_model.keras\n",
      "Epoch 7/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.3099 - accuracy: 0.4318 - val_loss: 1.2858 - val_accuracy: 0.4338\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.33622 to 1.28579, saving model to encoder_decoder_model.keras\n",
      "Epoch 8/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.2601 - accuracy: 0.4471 - val_loss: 1.2386 - val_accuracy: 0.4525\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.28579 to 1.23856, saving model to encoder_decoder_model.keras\n",
      "Epoch 9/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.2056 - accuracy: 0.4721 - val_loss: 1.1761 - val_accuracy: 0.4913\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.23856 to 1.17605, saving model to encoder_decoder_model.keras\n",
      "Epoch 10/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.1476 - accuracy: 0.5025 - val_loss: 1.1151 - val_accuracy: 0.4963\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.17605 to 1.11508, saving model to encoder_decoder_model.keras\n",
      "Epoch 11/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.0847 - accuracy: 0.5318 - val_loss: 1.0503 - val_accuracy: 0.5463\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.11508 to 1.05032, saving model to encoder_decoder_model.keras\n",
      "Epoch 12/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.0210 - accuracy: 0.5633 - val_loss: 0.9822 - val_accuracy: 0.5713\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.05032 to 0.98225, saving model to encoder_decoder_model.keras\n",
      "Epoch 13/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.9562 - accuracy: 0.5968 - val_loss: 0.9127 - val_accuracy: 0.6312\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.98225 to 0.91267, saving model to encoder_decoder_model.keras\n",
      "Epoch 14/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.8910 - accuracy: 0.6289 - val_loss: 0.8441 - val_accuracy: 0.6713\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.91267 to 0.84413, saving model to encoder_decoder_model.keras\n",
      "Epoch 15/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.8238 - accuracy: 0.6661 - val_loss: 0.7785 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.84413 to 0.77848, saving model to encoder_decoder_model.keras\n",
      "Epoch 16/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.7505 - accuracy: 0.7094 - val_loss: 0.7006 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.77848 to 0.70064, saving model to encoder_decoder_model.keras\n",
      "Epoch 17/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.6682 - accuracy: 0.7597 - val_loss: 0.6172 - val_accuracy: 0.7975\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.70064 to 0.61725, saving model to encoder_decoder_model.keras\n",
      "Epoch 18/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.5733 - accuracy: 0.8142 - val_loss: 0.5284 - val_accuracy: 0.8413\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.61725 to 0.52842, saving model to encoder_decoder_model.keras\n",
      "Epoch 19/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.4753 - accuracy: 0.8654 - val_loss: 0.4422 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.52842 to 0.44219, saving model to encoder_decoder_model.keras\n",
      "Epoch 20/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.9146 - val_loss: 0.3594 - val_accuracy: 0.9263\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.44219 to 0.35943, saving model to encoder_decoder_model.keras\n",
      "Epoch 21/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.3011 - accuracy: 0.9437 - val_loss: 0.2984 - val_accuracy: 0.9387\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35943 to 0.29845, saving model to encoder_decoder_model.keras\n",
      "Epoch 22/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.2346 - accuracy: 0.9643 - val_loss: 0.2377 - val_accuracy: 0.9625\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29845 to 0.23768, saving model to encoder_decoder_model.keras\n",
      "Epoch 23/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.9753 - val_loss: 0.1977 - val_accuracy: 0.9700\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.23768 to 0.19774, saving model to encoder_decoder_model.keras\n",
      "Epoch 24/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9849 - val_loss: 0.1669 - val_accuracy: 0.9688\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19774 to 0.16693, saving model to encoder_decoder_model.keras\n",
      "Epoch 25/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.1163 - accuracy: 0.9896 - val_loss: 0.1392 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.16693 to 0.13924, saving model to encoder_decoder_model.keras\n",
      "Epoch 26/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0941 - accuracy: 0.9922 - val_loss: 0.1179 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13924 to 0.11795, saving model to encoder_decoder_model.keras\n",
      "Epoch 27/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0760 - accuracy: 0.9953 - val_loss: 0.1073 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11795 to 0.10727, saving model to encoder_decoder_model.keras\n",
      "Epoch 28/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0628 - accuracy: 0.9964 - val_loss: 0.0873 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.10727 to 0.08728, saving model to encoder_decoder_model.keras\n",
      "Epoch 29/500\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9976 - val_loss: 0.0875 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.08728\n",
      "Epoch 30/500\n",
      "180/180 [==============================] - 2s 9ms/step - loss: 0.0421 - accuracy: 0.9985 - val_loss: 0.0724 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.08728 to 0.07238, saving model to encoder_decoder_model.keras\n",
      "Epoch 31/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0351 - accuracy: 0.9989 - val_loss: 0.0835 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07238\n",
      "Epoch 32/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0295 - accuracy: 0.9993 - val_loss: 0.0536 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.07238 to 0.05360, saving model to encoder_decoder_model.keras\n",
      "Epoch 33/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0244 - accuracy: 0.9997 - val_loss: 0.0483 - val_accuracy: 0.9888\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.05360 to 0.04830, saving model to encoder_decoder_model.keras\n",
      "Epoch 34/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0202 - accuracy: 0.9999 - val_loss: 0.0475 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04830 to 0.04753, saving model to encoder_decoder_model.keras\n",
      "Epoch 35/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.9999 - val_loss: 0.0436 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04753 to 0.04362, saving model to encoder_decoder_model.keras\n",
      "Epoch 36/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9999 - val_loss: 0.0348 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04362 to 0.03475, saving model to encoder_decoder_model.keras\n",
      "Epoch 37/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 0.9999 - val_loss: 0.0314 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.03475 to 0.03144, saving model to encoder_decoder_model.keras\n",
      "Epoch 38/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0106 - accuracy: 0.9999 - val_loss: 0.0263 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.03144 to 0.02631, saving model to encoder_decoder_model.keras\n",
      "Epoch 39/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.02631 to 0.02536, saving model to encoder_decoder_model.keras\n",
      "Epoch 40/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9999 - val_loss: 0.0273 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.02536\n",
      "Epoch 41/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.02536 to 0.01743, saving model to encoder_decoder_model.keras\n",
      "Epoch 42/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01743\n",
      "Epoch 43/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01743 to 0.01355, saving model to encoder_decoder_model.keras\n",
      "Epoch 44/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01355\n",
      "Epoch 45/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01355\n",
      "Epoch 46/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01355\n",
      "Epoch 47/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.01355 to 0.00989, saving model to encoder_decoder_model.keras\n",
      "Epoch 48/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00989\n",
      "Epoch 49/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00989\n",
      "Epoch 50/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00989 to 0.00812, saving model to encoder_decoder_model.keras\n",
      "Epoch 51/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00812 to 0.00659, saving model to encoder_decoder_model.keras\n",
      "Epoch 52/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9975\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00659\n",
      "Epoch 53/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00659 to 0.00582, saving model to encoder_decoder_model.keras\n",
      "Epoch 54/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00582\n",
      "Epoch 55/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 9.0892e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00582 to 0.00407, saving model to encoder_decoder_model.keras\n",
      "Epoch 56/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 7.7601e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00407\n",
      "Epoch 57/500\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 6.8031e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00407\n",
      "Epoch 58/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 5.8363e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00407 to 0.00311, saving model to encoder_decoder_model.keras\n",
      "Epoch 59/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 5.5159e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00311 to 0.00270, saving model to encoder_decoder_model.keras\n",
      "Epoch 60/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 4.7061e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00270 to 0.00217, saving model to encoder_decoder_model.keras\n",
      "Epoch 61/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 4.1800e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00217\n",
      "Epoch 62/500\n",
      "180/180 [==============================] - 1s 7ms/step - loss: 3.5289e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00217\n",
      "Epoch 63/500\n",
      "180/180 [==============================] - 1s 8ms/step - loss: 3.4301e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00217\n",
      "Epoch 64/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 2.8179e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00217 to 0.00196, saving model to encoder_decoder_model.keras\n",
      "Epoch 65/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 2.5600e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00196 to 0.00142, saving model to encoder_decoder_model.keras\n",
      "Epoch 66/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 2.7923e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00142\n",
      "Epoch 67/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 2.0211e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00142\n",
      "Epoch 68/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.7418e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00142\n",
      "Epoch 69/500\n",
      "180/180 [==============================] - 1s 6ms/step - loss: 1.6516e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00142\n",
      "Epoch 70/500\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 1.3602e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00142\n",
      "Epoch 00070: early stopping\n",
      "500  epoch training finished...\n",
      "\n",
      "PREDICTION ACCURACY (%):\n",
      "Train: 99.987, Test: 100.000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_test(model, X_train, y_train, X_test, y_test, batch_size=batch_size,epochs=500, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
